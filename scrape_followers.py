"""
Archivo: scrape_followers.py (PRINCIPAL)
Descripci√≥n: Orquestador principal del scraping (exposici√≥n posts_to_extract)
"""

from browser import init_browser
from auth import load_credentials, load_cookies, login, verify_session
from scraper import scrape_followers, collect_followers_data
from file_manager import save_followers_txt, save_followers_data_json
from benford_analysis import analizar_benford
from utils import human_delay


def main():
    """Funci√≥n principal"""
    print("\n" + "="*60)
    print("  INSTAGRAM FOLLOWERS SCRAPER + BENFORD ANALYSIS")
    print("="*60 + "\n")
    
    # Cargar credenciales
    username, password = load_credentials()
    
    # Inicializar navegador
    print("üåê Iniciando navegador...")
    driver = init_browser()
    
    try:
        # Autenticaci√≥n
        print("\nüîê Autenticando...")
        cookies_loaded = load_cookies(driver)
        
        if not cookies_loaded:
            print("üìù Login manual requerido...")
            if not login(driver, username, password):
                print("‚ùå Login fallido")
                return
        else:
            driver.get("https://www.instagram.com/")
            human_delay(3, 4)
            
            if not verify_session(driver):
                print("üîÑ Cookies inv√°lidas, reintentando login...")
                if not login(driver, username, password):
                    print("‚ùå Login fallido")
                    return
        
        # Solicitar datos
        print("\n" + "="*60)
        profile = input("üë§ Ingresa el username objetivo: ").strip()
        limit = int(input("üî¢ L√≠mite de seguidores a scrapear: "))
        posts_to_extract = int(input("üñºÔ∏è ¬øCu√°ntos captions por perfil extraer? (recomendado 1-3): ") or 3)
        posts_to_extract = max(0, min(posts_to_extract, 5))  # limitar entre 0 y 5
        
        # Scraping de followers
        print("\n" + "="*60)
        print("FASE 1: EXTRACCI√ìN DE FOLLOWERS")
        print("="*60)
        followers = scrape_followers(driver, profile, limit)
        
        if not followers:
            print("‚ùå No se encontraron followers.")
            return
        
        # Guardar lista de followers
        save_followers_txt(followers, profile)
        
        # Recopilar datos de followers
        print("\n" + "="*60)
        print("FASE 2: RECOPILACI√ìN DE DATOS")
        print("="*60)
        followers_data = collect_followers_data(driver, followers, max_profiles=limit, posts_to_extract=posts_to_extract)
        
        # Guardar datos JSON
        json_file = save_followers_data_json(followers_data, profile)
        
        # An√°lisis de Benford
        print("\n" + "="*60)
        print("FASE 3: AN√ÅLISIS DE BENFORD")
        print("="*60)
        benford_results = analizar_benford(json_file, profile)
        
        if benford_results:
            print("\n" + "="*60)
            print("‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
            print("="*60)
            print("\nüìÅ Archivos generados:")
            print(f"   ‚Ä¢ Lista de followers (TXT)")
            print(f"   ‚Ä¢ Datos de followers (JSON): {json_file}")
            print(f"   ‚Ä¢ An√°lisis Benford (XLSX): {benford_results['excel']}")
            print(f"   ‚Ä¢ Gr√°fica Benford (PNG): {benford_results['png']}")
            print("\n" + "="*60)
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Proceso interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        import traceback
        traceback.print_exc()
    finally:
        input("\n‚è∏Ô∏è  Presiona ENTER para cerrar el navegador...")
        driver.quit()
        print("üëã Navegador cerrado. Fin del programa.")
if __name__ == "__main__":
    main()
